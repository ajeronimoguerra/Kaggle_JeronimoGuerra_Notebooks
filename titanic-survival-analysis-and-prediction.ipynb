{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.15","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Titanic Survival Analysis and Prediction","metadata":{}},{"cell_type":"markdown","source":"This is a comprehensive Python solution for the Titanic competition.\n\n# Introduction\n\nIn this notebook, we delve into the infamous Titanic tragedy and utilize machine learning to predict passenger survival. We'll employ a combination of data cleaning, feature engineering, and advanced modeling techniques to uncover hidden insights and build a robust predictive model. Our analysis will focus on leveraging to improve accuracy and gain valuable knowledge from the historical data.","metadata":{}},{"cell_type":"markdown","source":"# Required libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd  # For data manipulation\nimport numpy as np  # For numerical operations\nfrom sklearn.model_selection import train_test_split  # For splitting data\nfrom sklearn.preprocessing import StandardScaler  # For scaling features\nfrom sklearn.ensemble import RandomForestClassifier  # The ML model\nfrom sklearn.impute import SimpleImputer  # For handling missing values\nfrom sklearn.metrics import accuracy_score, classification_report  # For evaluation","metadata":{"execution":{"iopub.status.busy":"2024-11-17T14:54:13.748345Z","iopub.execute_input":"2024-11-17T14:54:13.748800Z","iopub.status.idle":"2024-11-17T14:54:17.502757Z","shell.execute_reply.started":"2024-11-17T14:54:13.748766Z","shell.execute_reply":"2024-11-17T14:54:17.501927Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# 1. Load and inspect the Data","metadata":{}},{"cell_type":"markdown","source":"Download the competition data files (train.csv and test.csv) and place them in the same directory as the script.","metadata":{}},{"cell_type":"code","source":"# Load the data\ntrain_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-11-17T14:54:17.504202Z","iopub.execute_input":"2024-11-17T14:54:17.504513Z","iopub.status.idle":"2024-11-17T14:54:17.521998Z","shell.execute_reply.started":"2024-11-17T14:54:17.504487Z","shell.execute_reply":"2024-11-17T14:54:17.521272Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"**train.csv**: Contains data with known outcomes (in this case, whether passengers survived)\n\n* Used to train the model\n* Includes the target variable ('Survived')\n* Helps the model learn patterns\n\n\n**test.csv**: Contains data without the outcome\n\n* Used to make predictions on new data\n* Doesn't include the target variable\n* Tests how well your model generalizes to new data","metadata":{}},{"cell_type":"code","source":"print(\"\\nDataset Shape - train_data:\", train_data.shape)\nprint(\"\\nDataset Shape - test_data:\", test_data.shape)","metadata":{"execution":{"iopub.status.busy":"2024-11-17T14:54:17.523050Z","iopub.execute_input":"2024-11-17T14:54:17.523403Z","iopub.status.idle":"2024-11-17T14:54:17.527785Z","shell.execute_reply.started":"2024-11-17T14:54:17.523371Z","shell.execute_reply":"2024-11-17T14:54:17.527102Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\nDataset Shape - train_data: (891, 12)\n\nDataset Shape - test_data: (418, 11)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-17T14:54:17.529537Z","iopub.execute_input":"2024-11-17T14:54:17.529837Z","iopub.status.idle":"2024-11-17T14:54:17.553721Z","shell.execute_reply.started":"2024-11-17T14:54:17.529811Z","shell.execute_reply":"2024-11-17T14:54:17.553022Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-17T14:54:17.554473Z","iopub.execute_input":"2024-11-17T14:54:17.554697Z","iopub.status.idle":"2024-11-17T14:54:17.565019Z","shell.execute_reply.started":"2024-11-17T14:54:17.554675Z","shell.execute_reply":"2024-11-17T14:54:17.564412Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Pclass                                          Name     Sex  \\\n0          892       3                              Kelly, Mr. James    male   \n1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n2          894       2                     Myles, Mr. Thomas Francis    male   \n3          895       3                              Wirz, Mr. Albert    male   \n4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n\n    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n0  34.5      0      0   330911   7.8292   NaN        Q  \n1  47.0      1      0   363272   7.0000   NaN        S  \n2  62.0      0      0   240276   9.6875   NaN        Q  \n3  27.0      0      0   315154   8.6625   NaN        S  \n4  22.0      1      1  3101298  12.2875   NaN        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>3</td>\n      <td>Kelly, Mr. James</td>\n      <td>male</td>\n      <td>34.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330911</td>\n      <td>7.8292</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>3</td>\n      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n      <td>female</td>\n      <td>47.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>363272</td>\n      <td>7.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>2</td>\n      <td>Myles, Mr. Thomas Francis</td>\n      <td>male</td>\n      <td>62.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>240276</td>\n      <td>9.6875</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>3</td>\n      <td>Wirz, Mr. Albert</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>315154</td>\n      <td>8.6625</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>3</td>\n      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n      <td>female</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3101298</td>\n      <td>12.2875</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# 2. Data PreProcessing Function","metadata":{}},{"cell_type":"markdown","source":"* This function takes raw Titanic passenger data and cleans it up for machine learning\n\n* Key preprocessing steps include:\n    * Extracting titles from passenger names (Mr, Mrs, Miss, etc.)\n    * Creating family size features\n    * Handling missing values (age, fare, embarked status)\n    * Creating bins for fare and age ranges\n    * Converting categorical variables into numerical format (one-hot encoding)","metadata":{}},{"cell_type":"code","source":"def preprocess_data(df):\n    \"\"\"\n    Preprocess the Titanic dataset by handling missing values, creating new features,\n    and encoding categorical variables.\n    \"\"\"\n    # Create a copy to avoid modifying original data\n    data = df.copy()\n\n    # Extract titles from names\n    data['Title'] = data['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n    title_mapping = {\n        \"Mr\": \"Mr\",\n        \"Miss\": \"Miss\",\n        \"Mrs\": \"Mrs\",\n        \"Master\": \"Master\",\n        \"Dr\": \"Rare\",\n        \"Rev\": \"Rare\",\n        \"Col\": \"Rare\",\n        \"Major\": \"Rare\",\n        \"Mlle\": \"Miss\",\n        \"Countess\": \"Rare\",\n        \"Ms\": \"Miss\",\n        \"Lady\": \"Rare\",\n        \"Jonkheer\": \"Rare\",\n        \"Don\": \"Rare\",\n        \"Dona\": \"Rare\",\n        \"Mme\": \"Mrs\",\n        \"Capt\": \"Rare\",\n        \"Sir\": \"Rare\"\n    }\n    data['Title'] = data['Title'].map(title_mapping)\n\n    # Create family size feature where SibSp(siblings/spouses) and Parch(parents/children)\n    data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n\n    # Create is_alone feature for solo travelers\n    data['IsAlone'] = (data['FamilySize'] == 1).astype(int)\n\n    # Fill missing ages with median age by Title\n    data['Age'] = data.groupby('Title')['Age'].transform(\n        lambda x: x.fillna(x.median())\n    )\n\n    # Fill missing embarked with the most common port\n    data['Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()[0])\n\n    # Fill missing Fare with median fare\n    data['Fare'] = data['Fare'].fillna(data['Fare'].median())\n    \n    #Converts continous variables into categorical ranges    \n    # Create fare bins\n    data['FareBin'] = pd.qcut(data['Fare'], 4, labels=['Low', 'Mid', 'Mid-High', 'High'])\n\n    # Create age bins\n    data['AgeBin'] = pd.cut(data['Age'], 5, labels=['Child', 'Young', 'Adult', 'Middle', 'Senior'])\n\n    # Remove collumns that won´t be used for prediction\n    # Drop unnecessary columns\n    columns_to_drop = ['Name', 'Ticket', 'Cabin', 'PassengerId']\n    data = data.drop(columns_to_drop, axis=1)\n\n    # Convert categorical variables to dummy variables\n    categorical_columns = ['Sex', 'Embarked', 'Title', 'FareBin', 'AgeBin']\n    data = pd.get_dummies(data, columns=categorical_columns)\n\n    return data","metadata":{"execution":{"iopub.status.busy":"2024-11-17T14:54:17.565979Z","iopub.execute_input":"2024-11-17T14:54:17.566205Z","iopub.status.idle":"2024-11-17T14:54:17.576490Z","shell.execute_reply.started":"2024-11-17T14:54:17.566183Z","shell.execute_reply":"2024-11-17T14:54:17.575916Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# 3. Model Training Function","metadata":{}},{"cell_type":"markdown","source":"* Sets up and trains a Random Forest Classifier\n* Splits data into training and validation sets (80%/20%)\n* Prints out model performance metrics\n* Returns both the trained model and feature names","metadata":{}},{"cell_type":"code","source":"def train_model(train_data):\n    \"\"\"\n    Train a Random Forest model on the preprocessed data.\n    \"\"\"\n    # Separate features and target\n    X = train_data.drop('Survived', axis=1) # Features\n    y = train_data['Survived'] # Target variable\n    \n    # Split the data\n    X_train, X_val, y_train, y_val = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n    \n    # Initialize and train the model\n    model = RandomForestClassifier(\n        n_estimators=100, # Number of trees\n        max_depth=10, # Maximum tree depth\n        min_samples_split=5, # Minimum samples needed to split a node\n        min_samples_leaf=2, # Minimum samples in a leaf node\n        random_state=42 #For reproducibility\n    )\n    \n    model.fit(X_train, y_train)\n    \n    # Make predictions on validation set\n    val_predictions = model.predict(X_val)\n    \n    # Print validation metrics\n    print(\"\\nValidation Metrics:\")\n    print(\"Accuracy:\", accuracy_score(y_val, val_predictions))\n    print(\"\\nClassification Report:\")\n    print(classification_report(y_val, val_predictions))\n    \n    return model, X.columns","metadata":{"execution":{"iopub.status.busy":"2024-11-17T14:54:17.577199Z","iopub.execute_input":"2024-11-17T14:54:17.577406Z","iopub.status.idle":"2024-11-17T14:54:17.591807Z","shell.execute_reply.started":"2024-11-17T14:54:17.577384Z","shell.execute_reply":"2024-11-17T14:54:17.591195Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# 4. Prediction Function","metadata":{}},{"cell_type":"markdown","source":"* Takes new data and makes survival predictions\n* Ensures the test data matches the training data format\n* Creates a submission file with PassengerId and predictions","metadata":{}},{"cell_type":"code","source":"def make_predictions(model, feature_names, test_data):\n    \"\"\"\n    Make predictions on test data.\n    \"\"\"\n    # Preprocess test data\n    processed_test = preprocess_data(test_data)\n    \n    # Ensure test data has same columns as training data\n    for col in feature_names:\n        if col not in processed_test.columns:\n            processed_test[col] = 0\n    \n    # Reorder columns to match training data\n    processed_test = processed_test[feature_names]\n    \n    # Make predictions\n    predictions = model.predict(processed_test)\n    \n    # Create submission dataframe\n    submission = pd.DataFrame({\n        'PassengerId': test_data['PassengerId'],\n        'Survived': predictions\n    })\n    \n    return submission","metadata":{"execution":{"iopub.status.busy":"2024-11-17T14:54:17.592701Z","iopub.execute_input":"2024-11-17T14:54:17.592955Z","iopub.status.idle":"2024-11-17T14:54:17.609656Z","shell.execute_reply.started":"2024-11-17T14:54:17.592929Z","shell.execute_reply":"2024-11-17T14:54:17.609063Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"This will:\n* Preprocesses new test data using same steps as training data\n* Ensures all features match training data (adds missing columns if necessary)\n* Makes predictions on test data\n* Creates a submission file with predictions","metadata":{}},{"cell_type":"code","source":"\"\"\"\nTraining Data (100%)\n├── Training Set (80%) → Used to train the model\n└── Validation Set (20%) → Used to evaluate performance\n    └── This is where we got the metrics:\n        - Accuracy: 0.849\n        - Precision, Recall, F1-scores\n\nTest Data (100%)\n└── Used for final predictions\n    └── No metrics available because true values are unknown\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-11-17T14:54:17.610786Z","iopub.execute_input":"2024-11-17T14:54:17.611069Z","iopub.status.idle":"2024-11-17T14:54:17.620396Z","shell.execute_reply.started":"2024-11-17T14:54:17.611044Z","shell.execute_reply":"2024-11-17T14:54:17.619839Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'\\nTraining Data (100%)\\n├── Training Set (80%) → Used to train the model\\n└── Validation Set (20%) → Used to evaluate performance\\n    └── This is where we got the metrics:\\n        - Accuracy: 0.849\\n        - Precision, Recall, F1-scores\\n\\nTest Data (100%)\\n└── Used for final predictions\\n    └── No metrics available because true values are unknown\\n'"},"metadata":{}}]},{"cell_type":"markdown","source":"# 5. MAIN EXECUTION BLOCK","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    \n    # Process, train, and predict\n    processed_train = preprocess_data(train_data)\n    model, feature_names = train_model(processed_train)\n    submission = make_predictions(model, feature_names, test_data)\n    \n    # Save predictions\n    submission.to_csv('submission.csv', index=False)\n    \n    # Show sample of predictions\n    print('\\nSample of Predictions:')\n    print(submission.sample(10))","metadata":{"execution":{"iopub.status.busy":"2024-11-17T14:54:17.622310Z","iopub.execute_input":"2024-11-17T14:54:17.622764Z","iopub.status.idle":"2024-11-17T14:54:17.844392Z","shell.execute_reply.started":"2024-11-17T14:54:17.622734Z","shell.execute_reply":"2024-11-17T14:54:17.843676Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"\nValidation Metrics:\nAccuracy: 0.8491620111731844\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.87      0.88      0.87       105\n           1       0.82      0.81      0.82        74\n\n    accuracy                           0.85       179\n   macro avg       0.84      0.84      0.84       179\nweighted avg       0.85      0.85      0.85       179\n\n\nSample of Predictions:\n     PassengerId  Survived\n32           924         1\n241         1133         1\n372         1264         0\n293         1185         0\n168         1060         1\n326         1218         1\n188         1080         0\n238         1130         1\n142         1034         0\n186         1078         1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Titanic survival prediction model results\n\n\n1. **Overall Accuracy: 0.849 (or 84.9%)**\n- This means the model correctly predicted survival/non-survival for about 85% of the passengers in the validation set\n- Out of 179 total passengers in the validation set, the model correctly classified roughly 152 passengers\n- This is generally a good accuracy for the Titanic dataset, as it's well above random chance (50%)\n\n2. **Classification Report Breakdown:**\n\nThe report shows metrics for two classes:\n- Class 0: Did not survive\n- Class 1: Survived\n\nLet's analyze each metric:\n\na) **For Non-Survivors (Class 0):**\n- Precision: 0.87\n  - Of all passengers predicted to die, 87% actually did die\n  - Low false positive rate (rarely predicted death for survivors)\n- Recall: 0.88\n  - Of all passengers who actually died, the model identified 88% of them\n  - The model caught most of the actual deaths\n- F1-score: 0.87\n  - Harmonic mean of precision and recall\n  - Shows balanced performance between precision and recall\n- Support: 105\n  - There were 105 non-survivors in the validation set\n\nb) **For Survivors (Class 1):**\n- Precision: 0.82\n  - Of all passengers predicted to survive, 82% actually survived\n  - Slightly more false positives than with death predictions\n- Recall: 0.81\n  - Of all passengers who actually survived, the model identified 81% of them\n  - Slightly more missed survivors than missed deaths\n- F1-score: 0.82\n  - Shows balanced performance between precision and recall\n- Support: 74\n  - There were 74 survivors in the validation set\n\n3. **Macro vs Weighted Averages:**\n- Macro avg (0.84): Simple average of metrics across both classes\n- Weighted avg (0.85): Average weighted by class size (more weight to non-survivors since there were more of them)\n\n**Key Conclusions:**\n\n1. **Model Performance:**\n   - The model is performing well with 85% accuracy\n   - It's significantly better than random guessing (50%)\n   - Performance is balanced between survivors and non-survivors\n\n2. **Class Balance:**\n   - The validation set has more non-survivors (105) than survivors (74)\n   - This reflects the historical reality of the Titanic disaster\n\n3. **Prediction Quality:**\n   - Slightly better at predicting deaths (87-88%) than survivals (81-82%)\n   - Very balanced between precision and recall for both classes\n   - Few false positives in either direction\n\n4. **Model Reliability:**\n   - The model is slightly more reliable when predicting deaths than survivals\n   - The small difference between macro and weighted averages suggests good performance across both classes\n\n**Potential Areas for Improvement:**\n1. The gap between survivor and non-survivor prediction accuracy could potentially be narrowed\n2. The recall for survivors (0.81) could potentially be improved to catch more actual survivors\n3. Consider if the slightly better performance for non-survivors is acceptable given the use case","metadata":{}}]}