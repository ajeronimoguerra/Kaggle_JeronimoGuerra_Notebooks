{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad386051",
   "metadata": {
    "papermill": {
     "duration": 0.007918,
     "end_time": "2024-11-08T21:06:38.115839",
     "exception": false,
     "start_time": "2024-11-08T21:06:38.107921",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Titanic Survival Analysis and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd30aa70",
   "metadata": {
    "papermill": {
     "duration": 0.006987,
     "end_time": "2024-11-08T21:06:38.130272",
     "exception": false,
     "start_time": "2024-11-08T21:06:38.123285",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This is a comprehensive Python solution for the Titanic competition.\n",
    "\n",
    "# Introduction\n",
    "\n",
    "In this notebook, we delve into the infamous Titanic tragedy and utilize machine learning to predict passenger survival. We'll employ a combination of data cleaning, feature engineering, and advanced modeling techniques to uncover hidden insights and build a robust predictive model. Our analysis will focus on leveraging to improve accuracy and gain valuable knowledge from the historical data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43334833",
   "metadata": {
    "papermill": {
     "duration": 0.006952,
     "end_time": "2024-11-08T21:06:38.144495",
     "exception": false,
     "start_time": "2024-11-08T21:06:38.137543",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "467e6fac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T21:06:38.160852Z",
     "iopub.status.busy": "2024-11-08T21:06:38.160400Z",
     "iopub.status.idle": "2024-11-08T21:06:41.335424Z",
     "shell.execute_reply": "2024-11-08T21:06:41.334309Z"
    },
    "papermill": {
     "duration": 3.186414,
     "end_time": "2024-11-08T21:06:41.338202",
     "exception": false,
     "start_time": "2024-11-08T21:06:38.151788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd  # For data manipulation\n",
    "import numpy as np  # For numerical operations\n",
    "from sklearn.model_selection import train_test_split  # For splitting data\n",
    "from sklearn.preprocessing import StandardScaler  # For scaling features\n",
    "from sklearn.ensemble import RandomForestClassifier  # The ML model\n",
    "from sklearn.impute import SimpleImputer  # For handling missing values\n",
    "from sklearn.metrics import accuracy_score, classification_report  # For evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49043b03",
   "metadata": {
    "papermill": {
     "duration": 0.006954,
     "end_time": "2024-11-08T21:06:41.352440",
     "exception": false,
     "start_time": "2024-11-08T21:06:41.345486",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Load and inspect the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fa4732",
   "metadata": {
    "papermill": {
     "duration": 0.00686,
     "end_time": "2024-11-08T21:06:41.366485",
     "exception": false,
     "start_time": "2024-11-08T21:06:41.359625",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Download the competition data files (train.csv and test.csv) and place them in the same directory as the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "614d711a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T21:06:41.384715Z",
     "iopub.status.busy": "2024-11-08T21:06:41.383565Z",
     "iopub.status.idle": "2024-11-08T21:06:41.416379Z",
     "shell.execute_reply": "2024-11-08T21:06:41.415290Z"
    },
    "papermill": {
     "duration": 0.044094,
     "end_time": "2024-11-08T21:06:41.419129",
     "exception": false,
     "start_time": "2024-11-08T21:06:41.375035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
    "test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11c8d9e",
   "metadata": {
    "papermill": {
     "duration": 0.007208,
     "end_time": "2024-11-08T21:06:41.434382",
     "exception": false,
     "start_time": "2024-11-08T21:06:41.427174",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**train.csv**: Contains data with known outcomes (in this case, whether passengers survived)\n",
    "\n",
    "* Used to train the model\n",
    "* Includes the target variable ('Survived')\n",
    "* Helps the model learn patterns\n",
    "\n",
    "\n",
    "**test.csv**: Contains data without the outcome\n",
    "\n",
    "* Used to make predictions on new data\n",
    "* Doesn't include the target variable\n",
    "* Tests how well your model generalizes to new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8a7a776",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T21:06:41.450686Z",
     "iopub.status.busy": "2024-11-08T21:06:41.450214Z",
     "iopub.status.idle": "2024-11-08T21:06:41.457385Z",
     "shell.execute_reply": "2024-11-08T21:06:41.456084Z"
    },
    "papermill": {
     "duration": 0.018105,
     "end_time": "2024-11-08T21:06:41.459824",
     "exception": false,
     "start_time": "2024-11-08T21:06:41.441719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Shape - train_data: (891, 12)\n",
      "\n",
      "Dataset Shape - test_data: (418, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDataset Shape - train_data:\", train_data.shape)\n",
    "print(\"\\nDataset Shape - test_data:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99d7315a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T21:06:41.477158Z",
     "iopub.status.busy": "2024-11-08T21:06:41.476710Z",
     "iopub.status.idle": "2024-11-08T21:06:41.507653Z",
     "shell.execute_reply": "2024-11-08T21:06:41.506443Z"
    },
    "papermill": {
     "duration": 0.042914,
     "end_time": "2024-11-08T21:06:41.510369",
     "exception": false,
     "start_time": "2024-11-08T21:06:41.467455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d337f62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T21:06:41.528331Z",
     "iopub.status.busy": "2024-11-08T21:06:41.527906Z",
     "iopub.status.idle": "2024-11-08T21:06:41.546100Z",
     "shell.execute_reply": "2024-11-08T21:06:41.544786Z"
    },
    "papermill": {
     "duration": 0.030667,
     "end_time": "2024-11-08T21:06:41.548898",
     "exception": false,
     "start_time": "2024-11-08T21:06:41.518231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027993bf",
   "metadata": {
    "papermill": {
     "duration": 0.007818,
     "end_time": "2024-11-08T21:06:41.565302",
     "exception": false,
     "start_time": "2024-11-08T21:06:41.557484",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Data PreProcessing Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f40242",
   "metadata": {
    "papermill": {
     "duration": 0.008043,
     "end_time": "2024-11-08T21:06:41.581574",
     "exception": false,
     "start_time": "2024-11-08T21:06:41.573531",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* This function takes raw Titanic passenger data and cleans it up for machine learning\n",
    "\n",
    "* Key preprocessing steps include:\n",
    "    * Extracting titles from passenger names (Mr, Mrs, Miss, etc.)\n",
    "    * Creating family size features\n",
    "    * Handling missing values (age, fare, embarked status)\n",
    "    * Creating bins for fare and age ranges\n",
    "    * Converting categorical variables into numerical format (one-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a47c8489",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T21:06:41.599398Z",
     "iopub.status.busy": "2024-11-08T21:06:41.598942Z",
     "iopub.status.idle": "2024-11-08T21:06:41.613856Z",
     "shell.execute_reply": "2024-11-08T21:06:41.612729Z"
    },
    "papermill": {
     "duration": 0.026623,
     "end_time": "2024-11-08T21:06:41.616282",
     "exception": false,
     "start_time": "2024-11-08T21:06:41.589659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess the Titanic dataset by handling missing values, creating new features,\n",
    "    and encoding categorical variables.\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying original data\n",
    "    data = df.copy()\n",
    "\n",
    "    # Extract titles from names\n",
    "    data['Title'] = data['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    title_mapping = {\n",
    "        \"Mr\": \"Mr\",\n",
    "        \"Miss\": \"Miss\",\n",
    "        \"Mrs\": \"Mrs\",\n",
    "        \"Master\": \"Master\",\n",
    "        \"Dr\": \"Rare\",\n",
    "        \"Rev\": \"Rare\",\n",
    "        \"Col\": \"Rare\",\n",
    "        \"Major\": \"Rare\",\n",
    "        \"Mlle\": \"Miss\",\n",
    "        \"Countess\": \"Rare\",\n",
    "        \"Ms\": \"Miss\",\n",
    "        \"Lady\": \"Rare\",\n",
    "        \"Jonkheer\": \"Rare\",\n",
    "        \"Don\": \"Rare\",\n",
    "        \"Dona\": \"Rare\",\n",
    "        \"Mme\": \"Mrs\",\n",
    "        \"Capt\": \"Rare\",\n",
    "        \"Sir\": \"Rare\"\n",
    "    }\n",
    "    data['Title'] = data['Title'].map(title_mapping)\n",
    "\n",
    "    # Create family size feature where SibSp(siblings/spouses) and Parch(parents/children)\n",
    "    data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n",
    "\n",
    "    # Create is_alone feature for solo travelers\n",
    "    data['IsAlone'] = (data['FamilySize'] == 1).astype(int)\n",
    "\n",
    "    # Fill missing ages with median age by Title\n",
    "    data['Age'] = data.groupby('Title')['Age'].transform(\n",
    "        lambda x: x.fillna(x.median())\n",
    "    )\n",
    "\n",
    "    # Fill missing embarked with the most common port\n",
    "    data['Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()[0])\n",
    "\n",
    "    # Fill missing Fare with median fare\n",
    "    data['Fare'] = data['Fare'].fillna(data['Fare'].median())\n",
    "    \n",
    "    #Converts continous variables into categorical ranges    \n",
    "    # Create fare bins\n",
    "    data['FareBin'] = pd.qcut(data['Fare'], 4, labels=['Low', 'Mid', 'Mid-High', 'High'])\n",
    "\n",
    "    # Create age bins\n",
    "    data['AgeBin'] = pd.cut(data['Age'], 5, labels=['Child', 'Young', 'Adult', 'Middle', 'Senior'])\n",
    "\n",
    "    # Remove collumns that won´t be used for prediction\n",
    "    # Drop unnecessary columns\n",
    "    columns_to_drop = ['Name', 'Ticket', 'Cabin', 'PassengerId']\n",
    "    data = data.drop(columns_to_drop, axis=1)\n",
    "\n",
    "    # Convert categorical variables to dummy variables\n",
    "    categorical_columns = ['Sex', 'Embarked', 'Title', 'FareBin', 'AgeBin']\n",
    "    data = pd.get_dummies(data, columns=categorical_columns)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005fb1e0",
   "metadata": {
    "papermill": {
     "duration": 0.007627,
     "end_time": "2024-11-08T21:06:41.631957",
     "exception": false,
     "start_time": "2024-11-08T21:06:41.624330",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Model Training Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59477084",
   "metadata": {
    "papermill": {
     "duration": 0.007817,
     "end_time": "2024-11-08T21:06:41.648191",
     "exception": false,
     "start_time": "2024-11-08T21:06:41.640374",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Sets up and trains a Random Forest Classifier\n",
    "* Splits data into training and validation sets (80%/20%)\n",
    "* Prints out model performance metrics\n",
    "* Returns both the trained model and feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7672affe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T21:06:41.665906Z",
     "iopub.status.busy": "2024-11-08T21:06:41.665486Z",
     "iopub.status.idle": "2024-11-08T21:06:41.674570Z",
     "shell.execute_reply": "2024-11-08T21:06:41.673420Z"
    },
    "papermill": {
     "duration": 0.02088,
     "end_time": "2024-11-08T21:06:41.676989",
     "exception": false,
     "start_time": "2024-11-08T21:06:41.656109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(train_data):\n",
    "    \"\"\"\n",
    "    Train a Random Forest model on the preprocessed data.\n",
    "    \"\"\"\n",
    "    # Separate features and target\n",
    "    X = train_data.drop('Survived', axis=1) # Features\n",
    "    y = train_data['Survived'] # Target variable\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Initialize and train the model\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100, # Number of trees\n",
    "        max_depth=10, # Maximum tree depth\n",
    "        min_samples_split=5, # Minimum samples needed to split a node\n",
    "        min_samples_leaf=2, # Minimum samples in a leaf node\n",
    "        random_state=42 #For reproducibility\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on validation set\n",
    "    val_predictions = model.predict(X_val)\n",
    "    \n",
    "    # Print validation metrics\n",
    "    print(\"\\nValidation Metrics:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_val, val_predictions))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_val, val_predictions))\n",
    "    \n",
    "    return model, X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477c4476",
   "metadata": {
    "papermill": {
     "duration": 0.007741,
     "end_time": "2024-11-08T21:06:41.692751",
     "exception": false,
     "start_time": "2024-11-08T21:06:41.685010",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Prediction Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623fe4aa",
   "metadata": {
    "papermill": {
     "duration": 0.007635,
     "end_time": "2024-11-08T21:06:41.708516",
     "exception": false,
     "start_time": "2024-11-08T21:06:41.700881",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Takes new data and makes survival predictions\n",
    "* Ensures the test data matches the training data format\n",
    "* Creates a submission file with PassengerId and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "318c04e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T21:06:41.726716Z",
     "iopub.status.busy": "2024-11-08T21:06:41.725874Z",
     "iopub.status.idle": "2024-11-08T21:06:41.733248Z",
     "shell.execute_reply": "2024-11-08T21:06:41.732072Z"
    },
    "papermill": {
     "duration": 0.019134,
     "end_time": "2024-11-08T21:06:41.735646",
     "exception": false,
     "start_time": "2024-11-08T21:06:41.716512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_predictions(model, feature_names, test_data):\n",
    "    \"\"\"\n",
    "    Make predictions on test data.\n",
    "    \"\"\"\n",
    "    # Preprocess test data\n",
    "    processed_test = preprocess_data(test_data)\n",
    "    \n",
    "    # Ensure test data has same columns as training data\n",
    "    for col in feature_names:\n",
    "        if col not in processed_test.columns:\n",
    "            processed_test[col] = 0\n",
    "    \n",
    "    # Reorder columns to match training data\n",
    "    processed_test = processed_test[feature_names]\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(processed_test)\n",
    "    \n",
    "    # Create submission dataframe\n",
    "    submission = pd.DataFrame({\n",
    "        'PassengerId': test_data['PassengerId'],\n",
    "        'Survived': predictions\n",
    "    })\n",
    "    \n",
    "    return submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5d505e",
   "metadata": {
    "papermill": {
     "duration": 0.008283,
     "end_time": "2024-11-08T21:06:41.751984",
     "exception": false,
     "start_time": "2024-11-08T21:06:41.743701",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This will:\n",
    "* Preprocesses new test data using same steps as training data\n",
    "* Ensures all features match training data (adds missing columns if necessary)\n",
    "* Makes predictions on test data\n",
    "* Creates a submission file with predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3444d285",
   "metadata": {
    "papermill": {
     "duration": 0.007761,
     "end_time": "2024-11-08T21:06:41.767920",
     "exception": false,
     "start_time": "2024-11-08T21:06:41.760159",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. MAIN EXECUTION BLOCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "827a6457",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T21:06:41.786066Z",
     "iopub.status.busy": "2024-11-08T21:06:41.785606Z",
     "iopub.status.idle": "2024-11-08T21:06:42.176679Z",
     "shell.execute_reply": "2024-11-08T21:06:42.175424Z"
    },
    "papermill": {
     "duration": 0.403528,
     "end_time": "2024-11-08T21:06:42.179521",
     "exception": false,
     "start_time": "2024-11-08T21:06:41.775993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Metrics:\n",
      "Accuracy: 0.8491620111731844\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87       105\n",
      "           1       0.82      0.81      0.82        74\n",
      "\n",
      "    accuracy                           0.85       179\n",
      "   macro avg       0.84      0.84      0.84       179\n",
      "weighted avg       0.85      0.85      0.85       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Process, train, and predict\n",
    "    processed_train = preprocess_data(train_data)\n",
    "    model, feature_names = train_model(processed_train)\n",
    "    submission = make_predictions(model, feature_names, test_data)\n",
    "    \n",
    "    # Save predictions\n",
    "    submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11983380",
   "metadata": {
    "papermill": {
     "duration": 0.00774,
     "end_time": "2024-11-08T21:06:42.195590",
     "exception": false,
     "start_time": "2024-11-08T21:06:42.187850",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Titanic survival prediction model results\n",
    "\n",
    "\n",
    "1. **Overall Accuracy: 0.849 (or 84.9%)**\n",
    "- This means the model correctly predicted survival/non-survival for about 85% of the passengers in the validation set\n",
    "- Out of 179 total passengers in the validation set, the model correctly classified roughly 152 passengers\n",
    "- This is generally a good accuracy for the Titanic dataset, as it's well above random chance (50%)\n",
    "\n",
    "2. **Classification Report Breakdown:**\n",
    "\n",
    "The report shows metrics for two classes:\n",
    "- Class 0: Did not survive\n",
    "- Class 1: Survived\n",
    "\n",
    "Let's analyze each metric:\n",
    "\n",
    "a) **For Non-Survivors (Class 0):**\n",
    "- Precision: 0.87\n",
    "  - Of all passengers predicted to die, 87% actually did die\n",
    "  - Low false positive rate (rarely predicted death for survivors)\n",
    "- Recall: 0.88\n",
    "  - Of all passengers who actually died, the model identified 88% of them\n",
    "  - The model caught most of the actual deaths\n",
    "- F1-score: 0.87\n",
    "  - Harmonic mean of precision and recall\n",
    "  - Shows balanced performance between precision and recall\n",
    "- Support: 105\n",
    "  - There were 105 non-survivors in the validation set\n",
    "\n",
    "b) **For Survivors (Class 1):**\n",
    "- Precision: 0.82\n",
    "  - Of all passengers predicted to survive, 82% actually survived\n",
    "  - Slightly more false positives than with death predictions\n",
    "- Recall: 0.81\n",
    "  - Of all passengers who actually survived, the model identified 81% of them\n",
    "  - Slightly more missed survivors than missed deaths\n",
    "- F1-score: 0.82\n",
    "  - Shows balanced performance between precision and recall\n",
    "- Support: 74\n",
    "  - There were 74 survivors in the validation set\n",
    "\n",
    "3. **Macro vs Weighted Averages:**\n",
    "- Macro avg (0.84): Simple average of metrics across both classes\n",
    "- Weighted avg (0.85): Average weighted by class size (more weight to non-survivors since there were more of them)\n",
    "\n",
    "**Key Conclusions:**\n",
    "\n",
    "1. **Model Performance:**\n",
    "   - The model is performing well with 85% accuracy\n",
    "   - It's significantly better than random guessing (50%)\n",
    "   - Performance is balanced between survivors and non-survivors\n",
    "\n",
    "2. **Class Balance:**\n",
    "   - The validation set has more non-survivors (105) than survivors (74)\n",
    "   - This reflects the historical reality of the Titanic disaster\n",
    "\n",
    "3. **Prediction Quality:**\n",
    "   - Slightly better at predicting deaths (87-88%) than survivals (81-82%)\n",
    "   - Very balanced between precision and recall for both classes\n",
    "   - Few false positives in either direction\n",
    "\n",
    "4. **Model Reliability:**\n",
    "   - The model is slightly more reliable when predicting deaths than survivals\n",
    "   - The small difference between macro and weighted averages suggests good performance across both classes\n",
    "\n",
    "**Potential Areas for Improvement:**\n",
    "1. The gap between survivor and non-survivor prediction accuracy could potentially be narrowed\n",
    "2. The recall for survivors (0.81) could potentially be improved to catch more actual survivors\n",
    "3. Consider if the slightly better performance for non-survivors is acceptable given the use case\n",
    "\n",
    "Would you like me to elaborate on any of these aspects or explain how we might try to improve the model's performance further?"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.123812,
   "end_time": "2024-11-08T21:06:42.926623",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-08T21:06:34.802811",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
